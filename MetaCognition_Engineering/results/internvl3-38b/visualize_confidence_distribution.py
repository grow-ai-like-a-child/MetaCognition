#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯è§†åŒ–InternVL3-38Bæ¯ç±»ä»»åŠ¡çš„ç½®ä¿¡åº¦åˆ†å¸ƒ
"""

import json
import matplotlib.pyplot as plt
import numpy as np
from collections import defaultdict
from pathlib import Path

def create_confidence_visualization():
    """
    åˆ›å»ºç½®ä¿¡åº¦åˆ†å¸ƒå¯è§†åŒ–
    """
    # åŠ è½½åˆ†æç»“æœ
    analysis_file = Path("internvl3_confidence_by_task_analysis.json")
    with open(analysis_file, 'r', encoding='utf-8') as f:
        analysis_data = json.load(f)
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'Arial Unicode MS']
    plt.rcParams['axes.unicode_minus'] = False
    
    # åˆ›å»ºå­å›¾
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('InternVL3-38B æ¯ç±»ä»»åŠ¡ç½®ä¿¡åº¦åˆ†å¸ƒåˆ†æ', fontsize=16, fontweight='bold')
    
    # 1. ç½®ä¿¡åº¦åˆ†å¸ƒé¥¼å›¾
    ax1 = axes[0, 0]
    tasks = list(analysis_data.keys())
    colors = ['#ff9999', '#66b3ff', '#99ff99']
    
    # ä¸ºæ¯ä¸ªä»»åŠ¡åˆ›å»ºç½®ä¿¡åº¦åˆ†å¸ƒ
    conf3_data = [analysis_data[task]['confidence_distribution'].get('3', 0) for task in tasks]
    conf4_data = [analysis_data[task]['confidence_distribution'].get('4', 0) for task in tasks]
    conf5_data = [analysis_data[task]['confidence_distribution'].get('5', 0) for task in tasks]
    
    x = np.arange(len(tasks))
    width = 0.25
    
    ax1.bar(x - width, conf3_data, width, label='ç½®ä¿¡åº¦ 3', color='#ff9999', alpha=0.8)
    ax1.bar(x, conf4_data, width, label='ç½®ä¿¡åº¦ 4', color='#66b3ff', alpha=0.8)
    ax1.bar(x + width, conf5_data, width, label='ç½®ä¿¡åº¦ 5', color='#99ff99', alpha=0.8)
    
    ax1.set_xlabel('ä»»åŠ¡ç±»å‹')
    ax1.set_ylabel('é¢˜ç›®æ•°é‡')
    ax1.set_title('å„ä»»åŠ¡ç½®ä¿¡åº¦åˆ†å¸ƒ')
    ax1.set_xticks(x)
    ax1.set_xticklabels(tasks)
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. ç½®ä¿¡åº¦ç™¾åˆ†æ¯”åˆ†å¸ƒ
    ax2 = axes[0, 1]
    
    # è®¡ç®—ç™¾åˆ†æ¯”
    conf3_pct = [conf3_data[i] / analysis_data[task]['total_questions'] * 100 for i, task in enumerate(tasks)]
    conf4_pct = [conf4_data[i] / analysis_data[task]['total_questions'] * 100 for i, task in enumerate(tasks)]
    conf5_pct = [conf5_data[i] / analysis_data[task]['total_questions'] * 100 for i, task in enumerate(tasks)]
    
    ax2.bar(x - width, conf3_pct, width, label='ç½®ä¿¡åº¦ 3', color='#ff9999', alpha=0.8)
    ax2.bar(x, conf4_pct, width, label='ç½®ä¿¡åº¦ 4', color='#66b3ff', alpha=0.8)
    ax2.bar(x + width, conf5_pct, width, label='ç½®ä¿¡åº¦ 5', color='#99ff99', alpha=0.8)
    
    ax2.set_xlabel('ä»»åŠ¡ç±»å‹')
    ax2.set_ylabel('ç™¾åˆ†æ¯” (%)')
    ax2.set_title('å„ä»»åŠ¡ç½®ä¿¡åº¦ç™¾åˆ†æ¯”åˆ†å¸ƒ')
    ax2.set_xticks(x)
    ax2.set_xticklabels(tasks)
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. ç½®ä¿¡åº¦ä¸å‡†ç¡®ç‡å…³ç³»
    ax3 = axes[1, 0]
    
    conf_levels = [3, 4, 5]
    for i, task in enumerate(tasks):
        accuracies = []
        for conf in conf_levels:
            if conf in analysis_data[task]['confidence_accuracy']:
                accuracies.append(analysis_data[task]['confidence_accuracy'][conf])
            else:
                accuracies.append(0)
        
        ax3.plot(conf_levels, accuracies, marker='o', linewidth=2, label=task, color=colors[i])
    
    # æ·»åŠ ç†æƒ³æ ¡å‡†çº¿
    ideal_line = [conf/5.0 for conf in conf_levels]
    ax3.plot(conf_levels, ideal_line, 'k--', alpha=0.7, label='ç†æƒ³æ ¡å‡†çº¿')
    
    ax3.set_xlabel('ç½®ä¿¡åº¦')
    ax3.set_ylabel('å‡†ç¡®ç‡')
    ax3.set_title('ç½®ä¿¡åº¦ä¸å‡†ç¡®ç‡å…³ç³»')
    ax3.set_xticks(conf_levels)
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    ax3.set_ylim(0, 1)
    
    # 4. ä»»åŠ¡æ€§èƒ½å¯¹æ¯”
    ax4 = axes[1, 1]
    
    task_names = tasks
    accuracies = [analysis_data[task]['accuracy'] * 100 for task in tasks]
    avg_confidences = [analysis_data[task]['average_confidence'] for task in tasks]
    
    # åˆ›å»ºåŒè½´
    ax4_twin = ax4.twinx()
    
    bars = ax4.bar(task_names, accuracies, alpha=0.7, color=colors, label='å‡†ç¡®ç‡ (%)')
    line = ax4_twin.plot(task_names, avg_confidences, 'ro-', linewidth=2, markersize=8, label='å¹³å‡ç½®ä¿¡åº¦')
    
    ax4.set_xlabel('ä»»åŠ¡ç±»å‹')
    ax4.set_ylabel('å‡†ç¡®ç‡ (%)', color='blue')
    ax4_twin.set_ylabel('å¹³å‡ç½®ä¿¡åº¦', color='red')
    ax4.set_title('ä»»åŠ¡æ€§èƒ½ä¸å¹³å‡ç½®ä¿¡åº¦å¯¹æ¯”')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (acc, conf) in enumerate(zip(accuracies, avg_confidences)):
        ax4.text(i, acc + 1, f'{acc:.1f}%', ha='center', va='bottom')
        ax4_twin.text(i, conf + 0.05, f'{conf:.2f}', ha='center', va='bottom', color='red')
    
    ax4.grid(True, alpha=0.3)
    
    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    plt.savefig('internvl3_confidence_distribution.png', dpi=300, bbox_inches='tight')
    plt.savefig('internvl3_confidence_distribution.pdf', bbox_inches='tight')
    
    print("ğŸ“Š ç½®ä¿¡åº¦åˆ†å¸ƒå¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜:")
    print("   - internvl3_confidence_distribution.png")
    print("   - internvl3_confidence_distribution.pdf")
    
    # æ˜¾ç¤ºå›¾è¡¨
    plt.show()

def create_detailed_confidence_table():
    """
    åˆ›å»ºè¯¦ç»†çš„ç½®ä¿¡åº¦åˆ†å¸ƒè¡¨æ ¼
    """
    # åŠ è½½åˆ†æç»“æœ
    analysis_file = Path("internvl3_confidence_by_task_analysis.json")
    with open(analysis_file, 'r', encoding='utf-8') as f:
        analysis_data = json.load(f)
    
    print("\n" + "=" * 100)
    print("InternVL3-38B æ¯ç±»ä»»åŠ¡ç½®ä¿¡åº¦åˆ†å¸ƒè¯¦ç»†è¡¨æ ¼")
    print("=" * 100)
    
    for task in ['Color', 'Gabor', 'Grid']:
        if task not in analysis_data:
            continue
            
        data = analysis_data[task]
        print(f"\nğŸ“‹ {task} ä»»åŠ¡:")
        print("-" * 80)
        print(f"{'ç½®ä¿¡åº¦':<8} {'é¢˜ç›®æ•°':<8} {'ç™¾åˆ†æ¯”':<8} {'æ­£ç¡®æ•°':<8} {'å‡†ç¡®ç‡':<10} {'æ ¡å‡†è¯¯å·®':<10}")
        print("-" * 80)
        
        total = data['total_questions']
        for conf in [3, 4, 5]:
            count = data['confidence_distribution'].get(str(conf), 0)
            percentage = count / total * 100 if total > 0 else 0
            correct = int(count * data['confidence_accuracy'].get(str(conf), 0))
            accuracy = data['confidence_accuracy'].get(str(conf), 0)
            calibration_error = abs(accuracy - (conf / 5.0))
            
            print(f"{conf:<8} {count:<8} {percentage:<8.1f}% {correct:<8} {accuracy:<10.4f} {calibration_error:<10.4f}")
        
        print(f"\n   æ€»é¢˜ç›®æ•°: {total}")
        print(f"   å¹³å‡ç½®ä¿¡åº¦: {data['average_confidence']:.2f}")
        print(f"   æ•´ä½“å‡†ç¡®ç‡: {data['accuracy']:.4f} ({data['accuracy']*100:.2f}%)")

if __name__ == "__main__":
    try:
        create_confidence_visualization()
    except ImportError:
        print("matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆ")
        print("è¯·è¿è¡Œ: pip install matplotlib")
    
    create_detailed_confidence_table()
