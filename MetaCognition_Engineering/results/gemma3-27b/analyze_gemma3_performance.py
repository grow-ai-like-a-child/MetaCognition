#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æGemma3-27Bæ¨¡å‹æ€§èƒ½ï¼šæ­£ç¡®ç‡å’Œç½®ä¿¡åº¦ç»Ÿè®¡
"""

import json
import re
from collections import defaultdict
from pathlib import Path

def load_ground_truth():
    """
    åŠ è½½çœŸå®æ ‡ç­¾æ•°æ® - ä»ground_truth.jsonæ–‡ä»¶
    """
    ground_truth = {}
    
    # åŠ è½½ground_truth.jsonæ–‡ä»¶
    ground_truth_file = Path("../../data/raw/ground_truth.json")
    with open(ground_truth_file, 'r', encoding='utf-8') as f:
        gt_data = json.load(f)
    
    # æå–stage1é—®é¢˜çš„ç­”æ¡ˆï¼Œå¹¶è½¬æ¢ä¸ºoriginal_qidæ ¼å¼
    for qid, answer_data in gt_data.items():
        if '_stage1' in qid:
            # å°†qidè½¬æ¢ä¸ºoriginal_qid (å»æ‰_stage1åç¼€)
            original_qid = qid.replace('_stage1', '')
            correct_choice = answer_data.get('correct_choice')
            if correct_choice in ['A', 'B']:
                ground_truth[original_qid] = correct_choice
    
    return ground_truth

def analyze_model_performance():
    """
    åˆ†æGemma3æ¨¡å‹æ€§èƒ½
    """
    # åŠ è½½çœŸå®æ ‡ç­¾
    ground_truth = load_ground_truth()
    print(f"åŠ è½½äº† {len(ground_truth)} ä¸ªçœŸå®æ ‡ç­¾")
    
    # åŠ è½½æ¨¡å‹ç»“æœ
    results_file = Path("gemma3_27b_concise_full_results.jsonl")
    results = []
    
    with open(results_file, 'r', encoding='utf-8') as f:
        for line in f:
            results.append(json.loads(line.strip()))
    
    print(f"åŠ è½½äº† {len(results)} ä¸ªæ¨¡å‹ç»“æœ")
    
    # æŒ‰original_qidåˆ†ç»„ï¼Œåªåˆ†æstage1ç»“æœ
    stage1_results = {}
    stage2_results = {}
    
    for result in results:
        original_qid = result['original_qid']
        stage = result['stage']
        
        if stage == 1:
            stage1_results[original_qid] = result
        elif stage == 2:
            stage2_results[original_qid] = result
    
    print(f"æ‰¾åˆ° {len(stage1_results)} ä¸ªStage 1ç»“æœ")
    print(f"æ‰¾åˆ° {len(stage2_results)} ä¸ªStage 2ç»“æœ")
    
    # åˆ†æStage 1æ­£ç¡®ç‡
    print("\n" + "=" * 60)
    print("Gemma3-27B Stage 1 æ€§èƒ½åˆ†æ")
    print("=" * 60)
    
    correct_count = 0
    total_count = 0
    confidence_stats = defaultdict(lambda: {'total': 0, 'correct': 0})
    
    for original_qid, result in stage1_results.items():
        if original_qid not in ground_truth:
            continue
            
        total_count += 1
        predicted = result['choice']
        true_answer = ground_truth[original_qid]
        
        # æ£€æŸ¥æ˜¯å¦æ­£ç¡®
        is_correct = (predicted == true_answer)
        if is_correct:
            correct_count += 1
        
        # è·å–å¯¹åº”çš„Stage 2ç½®ä¿¡åº¦
        if original_qid in stage2_results:
            confidence = stage2_results[original_qid]['confidence']
            confidence_stats[confidence]['total'] += 1
            if is_correct:
                confidence_stats[confidence]['correct'] += 1
    
    # è®¡ç®—æ€»ä½“å‡†ç¡®ç‡
    overall_accuracy = correct_count / total_count if total_count > 0 else 0
    
    print(f"\nğŸ“Š Stage 1 æ€»ä½“æ€§èƒ½:")
    print(f"   æ€»é¢˜ç›®æ•°: {total_count}")
    print(f"   æ­£ç¡®ç­”æ¡ˆæ•°: {correct_count}")
    print(f"   æ•´ä½“å‡†ç¡®ç‡: {overall_accuracy:.4f} ({overall_accuracy*100:.2f}%)")
    
    # æŒ‰ç½®ä¿¡åº¦ç»Ÿè®¡
    print(f"\nğŸ“ˆ æŒ‰ç½®ä¿¡åº¦åˆ†ç»„ç»Ÿè®¡:")
    print("-" * 50)
    
    for conf in sorted(confidence_stats.keys()):
        stats = confidence_stats[conf]
        accuracy = stats['correct'] / stats['total'] if stats['total'] > 0 else 0
        percentage = stats['total'] / total_count * 100
        
        print(f"   ç½®ä¿¡åº¦ {conf}: {stats['correct']:4d}/{stats['total']:4d} = {accuracy:.4f} ({accuracy*100:5.2f}%) | å æ¯”: {percentage:5.2f}%")
    
    # æŒ‰ä»»åŠ¡ç±»å‹ç»Ÿè®¡
    print(f"\nğŸ“‹ æŒ‰ä»»åŠ¡ç±»å‹ç»Ÿè®¡:")
    print("-" * 50)
    
    task_stats = defaultdict(lambda: {'total': 0, 'correct': 0})
    
    for original_qid, result in stage1_results.items():
        if original_qid not in ground_truth:
            continue
            
        task = result.get('task', 'Unknown')
        predicted = result['choice']
        true_answer = ground_truth[original_qid]
        is_correct = (predicted == true_answer)
        
        task_stats[task]['total'] += 1
        if is_correct:
            task_stats[task]['correct'] += 1
    
    for task in sorted(task_stats.keys()):
        stats = task_stats[task]
        accuracy = stats['correct'] / stats['total'] if stats['total'] > 0 else 0
        percentage = stats['total'] / total_count * 100
        
        print(f"   {task:12s}: {stats['correct']:4d}/{stats['total']:4d} = {accuracy:.4f} ({accuracy*100:5.2f}%) | å æ¯”: {percentage:5.2f}%")
    
    # æ¦‚ç‡åˆ†æï¼ˆGemma3ç‰¹æœ‰çš„çœŸå®logitsæ¦‚ç‡ï¼‰
    print(f"\nğŸ² æ¦‚ç‡åˆ†æ (åŸºäºçœŸå®logits):")
    print("-" * 50)
    
    probability_stats = {
        'high_confidence': {'total': 0, 'correct': 0},  # Aæˆ–Bæ¦‚ç‡ > 0.8
        'medium_confidence': {'total': 0, 'correct': 0},  # 0.6 <= æ¦‚ç‡ <= 0.8
        'low_confidence': {'total': 0, 'correct': 0},   # æ¦‚ç‡ < 0.6
    }
    
    for original_qid, result in stage1_results.items():
        if original_qid not in ground_truth:
            continue
            
        predicted = result['choice']
        true_answer = ground_truth[original_qid]
        is_correct = (predicted == true_answer)
        
        # è·å–æ¦‚ç‡
        probs = result.get('probabilities', {})
        if predicted in probs:
            prob = probs[predicted]
            
            if prob > 0.8:
                category = 'high_confidence'
            elif prob >= 0.6:
                category = 'medium_confidence'
            else:
                category = 'low_confidence'
            
            probability_stats[category]['total'] += 1
            if is_correct:
                probability_stats[category]['correct'] += 1
    
    for category, stats in probability_stats.items():
        if stats['total'] > 0:
            accuracy = stats['correct'] / stats['total']
            percentage = stats['total'] / total_count * 100
            print(f"   {category:15s}: {stats['correct']:4d}/{stats['total']:4d} = {accuracy:.4f} ({accuracy*100:5.2f}%) | å æ¯”: {percentage:5.2f}%")
    
    # ç½®ä¿¡åº¦æ ¡å‡†åˆ†æ
    print(f"\nğŸ¯ ç½®ä¿¡åº¦æ ¡å‡†åˆ†æ:")
    print("-" * 50)
    
    # è®¡ç®—æ¯ä¸ªç½®ä¿¡åº¦æ°´å¹³çš„å¹³å‡å‡†ç¡®ç‡
    for conf in sorted(confidence_stats.keys()):
        stats = confidence_stats[conf]
        if stats['total'] > 0:
            accuracy = stats['correct'] / stats['total']
            calibration_error = abs(accuracy - (conf / 5.0))  # ç†æƒ³æƒ…å†µä¸‹ï¼Œç½®ä¿¡åº¦/5åº”è¯¥ç­‰äºå‡†ç¡®ç‡
            print(f"   ç½®ä¿¡åº¦ {conf}: å‡†ç¡®ç‡={accuracy:.3f}, ç†æƒ³å€¼={conf/5.0:.3f}, æ ¡å‡†è¯¯å·®={calibration_error:.3f}")
    
    # å»¶è¿Ÿåˆ†æ
    print(f"\nâ±ï¸ æ¨ç†å»¶è¿Ÿåˆ†æ:")
    print("-" * 50)
    
    stage1_latencies = [result.get('latency_ms', 0) for result in stage1_results.values()]
    stage2_latencies = [result.get('latency_ms', 0) for result in stage2_results.values()]
    
    if stage1_latencies:
        avg_stage1 = sum(stage1_latencies) / len(stage1_latencies)
        print(f"   Stage 1å¹³å‡å»¶è¿Ÿ: {avg_stage1:.1f}ms")
    
    if stage2_latencies:
        avg_stage2 = sum(stage2_latencies) / len(stage2_latencies)
        print(f"   Stage 2å¹³å‡å»¶è¿Ÿ: {avg_stage2:.1f}ms")
    
    if stage1_latencies and stage2_latencies:
        total_avg = (sum(stage1_latencies) + sum(stage2_latencies)) / (len(stage1_latencies) + len(stage2_latencies))
        print(f"   æ€»å¹³å‡å»¶è¿Ÿ: {total_avg:.1f}ms")
    
    # ä¿å­˜è¯¦ç»†æ¯”è¾ƒç»“æœ
    comparison_data = []
    for original_qid, result in stage1_results.items():
        if original_qid not in ground_truth:
            continue
            
        predicted = result['choice']
        true_answer = ground_truth[original_qid]
        is_correct = (predicted == true_answer)
        
        confidence = 0
        if original_qid in stage2_results:
            confidence = stage2_results[original_qid]['confidence']
        
        comparison_data.append({
            'original_qid': original_qid,
            'task': result.get('task', 'Unknown'),
            'predicted': predicted,
            'true_answer': true_answer,
            'is_correct': is_correct,
            'confidence': confidence,
            'probabilities': result.get('probabilities', {}),
            'latency_ms': result.get('latency_ms', 0),
            'stage1_latency': result.get('latency_ms', 0),
            'stage2_latency': stage2_results.get(original_qid, {}).get('latency_ms', 0) if original_qid in stage2_results else 0
        })
    
    # ä¿å­˜æ¯”è¾ƒç»“æœ
    with open('gemma3_comparison_with_ground_truth.json', 'w', encoding='utf-8') as f:
        json.dump(comparison_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ è¯¦ç»†æ¯”è¾ƒç»“æœå·²ä¿å­˜åˆ°: gemma3_comparison_with_ground_truth.json")
    print(f"   åŒ…å« {len(comparison_data)} ä¸ªé¢˜ç›®çš„è¯¦ç»†åˆ†æ")
    
    # æ‰“å°æ±‡æ€»ç»Ÿè®¡
    print(f"\nğŸ“ˆ æ±‡æ€»ç»Ÿè®¡:")
    print("-" * 50)
    print(f"   âœ… æ€»ä½“å‡†ç¡®ç‡: {overall_accuracy*100:.2f}%")
    print(f"   âš¡ å¹³å‡å»¶è¿Ÿ: {total_avg:.1f}ms" if 'total_avg' in locals() else "   âš¡ å»¶è¿Ÿä¿¡æ¯ä¸å®Œæ•´")
    print(f"   ğŸ¯ é«˜ç½®ä¿¡åº¦(5)å‡†ç¡®ç‡: {confidence_stats[5]['correct']/confidence_stats[5]['total']*100:.2f}%" if confidence_stats[5]['total'] > 0 else "   ğŸ¯ æ— ç½®ä¿¡åº¦5çš„æ•°æ®")
    print(f"   ğŸ“Š é«˜æ¦‚ç‡(>0.8)å‡†ç¡®ç‡: {probability_stats['high_confidence']['correct']/probability_stats['high_confidence']['total']*100:.2f}%" if probability_stats['high_confidence']['total'] > 0 else "   ğŸ“Š æ— é«˜æ¦‚ç‡æ•°æ®")

if __name__ == "__main__":
    analyze_model_performance()
